---
title: "Efficient Error Debugging and Handling with AI"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{minerr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(errormindR)
```

# Introduction

The `errormindR` package introduces AI-assisted tools to help R users diagnose and resolve errors more efficiently by interacting with a Large Language Model (LLM). This vignette demonstrates how to use two key functions: `minerr()` for analyzing errors with AI assistance and `minerr_log()` for accessing the communication log with the AI.

# The `minerr()` Function: AI-Assisted Error Diagnosis

The `minerr()` function helps you analyze an error by capturing the context and sending it to an LLM (such as OpenAI's GPT) for suggestions. The AI can provide explanations, potential fixes, and even code snippets to help you resolve the problem.

Note: The `minerr()` function can be used in two ways:

  1. As a piped expression (e.g., `some_code |> minerr()`), and
  2. By passing the code directly inside the function (e.g., `minerr(some_code)`).

For expressions like `ggplot2` plots, `if` statements, or `for` loops, piping will not capture errors correctly, because R evaluates these expressions lazily or delays execution until they are printed or run. To ensure proper error capture in these cases, always wrap the code block inside `minerr()` directly.

### Usage

```r
library(errormindR)

# Example
library(data.table)
dt <- as.data.table(mtcars)
dt[, .(cnt = .N), by = .("cyl", "gear")] |> minerr()

minerr(
  ggplot2::ggplot(df, aes(x, y))+
  geom_point()
)

x <- c(TRUE, FALSE)
minerr(
  if (x) {
    print("x is TRUE")
  }
)

```

When you call `minerr()`, it captures the error, sends a prompt to the AI model, and then prints the AI's response in the console. Optionally, it can insert the suggested code directly into your RStudio script editor.

### Key Arguments

- `.expr`: Expression. The code block that fails. If not pipe-able, then it must be provided inside parenthesis. e.g.: `minerr(code_here)`
- `is_logical_error`: Logical. Set to `TRUE` to indicate the error is a logical error. But must provide details via `chat` argument.
- `chat`: Optional. Provide additional information or questions for the AI.
- `share_full_context`: Logical. Set to `TRUE` to share the broader context of the session.
- `llm_func`: Optional. Allows you to specify a custom LLM function. By default, it uses OpenAI's GPT (4.1) model.
- `insert_code`: Logical. If `TRUE`, any suggested code from the AI will be inserted into your editor.

### Notes

- `minerr()` is designed to work interactively within RStudio.
- The function automatically captures the last error from the evaluated expression.
- If `insert_code` is TRUE (default) it'll insert the code where the cursor is. If you select your code and run, it'll replace that code with the AI generated solution.

# The `minerr_log()` Function: Reviewing AI Conversations

The `minerr_log()` function provides an easy way to retrieve or download the log of the last communication with the AI. This log contains program name, time stamp and the full text of the AI's response, which can be helpful for documentation, reporting, or further study.

### Viewing the Log in Console

```r
# Display the last AI chat log in the console
minerr_log()
```

### Downloading the Log as a File

```r
# Save the last AI chat log as a text file in the working directory
minerr_log(download = TRUE)
```

The downloaded log file is saved as `errormindR_last_chat_log.txt` in your current working directory.

# Summary

The `errormindR` package brings the power of AI to R error handling, making it easier and faster to understand and resolve coding issues.

- Use `minerr()` to automatically capture, analyze, and get suggestions for errors using an LLM.
- Use `minerr_log()` to access or save the conversation log with the AI.

We encourage you to experiment with these tools to enhance your R programming workflow and reduce debugging time.

